<!doctype html>
<html lang="en">
    <head>
        <title>SRUM: Fine-Grained Self-Rewarding for Unified Models</title>
        <link rel="icon" type="image/x-icon" href="/static/img/icons/icon.png">

        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <meta property="og:url" content="https://your-project-page-url.com/srum/" />
        <meta property="og:image" content="https://your-project-page-url.com/srum/static/img/preview.png" />
        <meta property="og:title" content="SRUM: Fine-Grained Self-Rewarding for Unified Models" />
        <meta property="og:description" content="Introducing SRUM, a self-rewarding framework that enables Unified Models to iteratively improve their generative capabilities by leveraging their own understanding." />

        <meta name="twitter:url" content="https://your-project-page-url.com/srum/" />
        <meta name="twitter:card" content="summary_large_image" />
        <meta name="twitter:image" content="https://your-project-page-url.com/srum/static/img/preview.png" />
        <meta name="twitter:title" content="SRUM: Fine-Grained Self-Rewarding for Unified Models" />
        <meta name="twitter:description" content="Introducing SRUM, a self-rewarding framework that enables Unified Models to iteratively improve their generative capabilities by leveraging their own understanding." />

        <script src="./static/js/distill_template.v2.js"></script>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

        <script src="https://d3js.org/d3.v5.min.js"></script>
        <script src="https://d3js.org/d3-collection.v1.min.js"></script>
        <script src="https://rawgit.com/nstrayer/slid3r/master/dist/slid3r.js"></script>

        <script defer="" src="./static/js/hider.js"></script>
        <script src="./static/js/image_interact.js"></script>
        <script src="./static/js/switch_videos.js"></script>

        <link rel="stylesheet" href="./static/css/style.css">
        <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js" integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script>
        <script defer src="./static/js/fontawesome.all.min.js"></script>


        <script src="https://cdn.jsdelivr.net/npm/jquery@3.7.1/dist/jquery.min.js"></script>  <script defer src="./static/js/medium-zoom.min.js"></script>
        <script defer src="./static/js/zoom.js"></script>
        <script defer src="./static/js/gallery.js"></script>
    </head>

    <body>
        <div class="header-wrapper">
            <div class="header-container" id="header-container">
                <div class="header-content">
                    <h1 style="margin-top: 0px"><i>SRUM: Fine-Grained Self-Rewarding for Unified Models</i></h1>
                        <p>
                           Introducing <strong>SRUM</strong> (<strong>S</strong>elf-<strong>R</strong>ewarding for <strong>U</strong>nified <strong>M</strong>odels), a post-training framework that creates a cost-effective, self-iterative optimization loop. SRUM compels a model's understanding component to enhance its generative component for better compositional reasoning and alignment.
                        </p>

                        <div class="icon-container">
                            <div class="icon-item">
                                <img src="./static/img/icons/self-reward.svg" alt="Self-Rewarding Icon">
                                <div><strong>Self-Rewarding Loop</strong>: SRUM leverages a Unified Model's own understanding module to provide internal reward signals to its generative module, eliminating the need for costly external judges. </div>
                            </div>
                            <div class="icon-item">
                                <img src="./static/img/icons/fine-grained.svg" alt="Fine-Grained Icon">
                                <div><strong>Fine-Grained Feedback</strong>: Our internal reward is decomposed into a </strong>global reward</strong> for overall compositional correctness and a </strong>local reward</strong> for attribute fidelity, enabling multi-scale refinement.</div>
                            </div>
                            <div class="icon-item">
                                <img src="./static/img/icons/sota.svg" alt="SOTA Icon">
                                <div><strong>State-of-the-Art Improvements</strong>: SRUM significantly improves compositional problems and reasoning generation, achieving SOTA results on T2I-CompBench (82.18 &rarr; 88.37) and T2I-ReasonBench (40.7 &rarr; 50.4 Acc.). </div>
                            </div>
                        </div>

                    <div class="button-container">
                        <a href="https://arxiv.org/abs/your_arxiv_id" class="button paper-link" target="_blank">
                            <span class="icon is-small">
                                <i class="ai ai-arxiv"></i>
                            </span>
                            arXiv
                        </a>
                        <a href="https://arxiv.org/pdf/your_arxiv_id.pdf" class="button paper-link" target="_blank">
                            <span class="icon is-small">
                                <i class="fas fa-file-pdf"></i>
                            </span>
                            <span>PDF</span>
                        </a>
                        <a href="https://github.com/WayneJin0918/SRUM" class="button" target="_blank">
                            <span class="icon is-small">
                                <i class="fab fa-github"></i>
                            </span>
                            <span>Code</span>
                        </a>
                    </div>
                </div>
                <div class="header-image">
                    <img draggable="false" src="static/img/taser_srum.png" alt="Teaser Image" class="teaser-image">
                </div>
            </div>
        </div>
    <d-article>
        <div class="byline">
            <div class="byline-container">
                <p>
                    <a href="https://github.com/WayneJin0918" class="author-link" target="_blank">Weiyang Jin<sup>*1,&dagger;</sup></a> &emsp;
                    <a href="https://purshow.github.io/" class="author-link" target="_blank">Purshow Niu<sup>*1</sup></a> &emsp;
                    <a href="" class="author-link" target="_blank">Curry Liao<sup>1</sup></a> &emsp;
                    <a href="https://scholar.google.com/citations?user=r9qb4ZwAAAAJ&hl=en" class="author-link" target="_blank">Chengqi Duan<sup>1</sup></a> &emsp;
                    <a href="https://xh-liu.github.io/" class="author-link" target="_blank">Xihui Liu<sup>1,&sect;</sup></a>
                    <p></p>
                </p>
                <p style="text-align: center;">
                    <a href="https://mmlab.hk/" class="affiliation-link" target="_blank"><sup>1</sup>HKU MMLab</a>
                </p>
                <p style="text-align: center; margin-bottom: 0;">
                    <span class="author-note"><sup>*</sup>Equal contribution, <sup>&dagger;</sup>Project lead, <sup>&sect;</sup>Corresponding Author</span>
                </p>
            </div>
        </div>
        <p class="text abstract">
            Unified Models (UMs), which integrate generative and understanding capabilities, face a key bottleneck: the disjointed training of their modules often leads to gradient conflicts and suboptimal performance. Standard Text-to-Image (T2I) models also struggle to interpret prompts requiring complex spatial relationships and compositional reasoning. 
            <br><br>
            To address this, we introduce <strong>SRUM</strong>, a self-rewarding post-training framework. The core idea is to leverage the UM's inherent duality: the understanding module evaluates and provides fine-grained reward signals to guide its own generative module. This creates a self-contained optimization loop that enhances the model's ability to handle complex prompts without relying on external judges. 

            This page is structured around three key components:
            <ol class="text">
                <li><strong><a href="#Methodology">&sect;Methodology</a></strong>: We detail the SRUM framework, including the rewarding process, the fine-grained judgment design (global and local rewards), and the weighted training objective.</li>
                <li><strong><a href="#Results">&sect;Results</a></strong>: We showcase how SRUM significantly boosts performance on challenging compositional benchmarks like T2I-CompBench and demonstrate its strong generalization capabilities.</li>
                <li><strong><a href="#Analysis">&sect;Analysis and Insights</a></strong>: We provide an empirical analysis of SRUM's components, revealing how different reward designs impact the model's inference process at various stages.</li>
            </ol>
        </p>

        <hr>

        <div id='Methodology' class="vision-block">
            <h1 class="text">How SRUM Works: A Three-Step Process</h1>
                <p class="text">
                    SRUM operates through a systematic, self-contained pipeline. The model first generates images, then critically evaluates its own output to create fine-grained rewards, and finally uses those rewards to refine itself via a weighted training objective. 
                </p>
                <d-figure>
                    <figure>
                        <img data-zoomable="" draggable="false" src="static/img/srum_ppl.png" alt="SRUM Pipeline">
                        <figcaption style="text-align: left;">
                            <strong>Figure 1:</strong> The pipeline of the SRUM framework. The process includes reward generation, the design of regional and global rewards, and their application during the post-training phase to refine the generative model. 
                        </figcaption>
                    </figure>
                </d-figure>

            <div id="sec:rewarding" class="sub-section">
                <h2 class="text">1. Rewarding Process</h2>
                <p class="text">
                    The rewarding process begins with the UM generating candidate images from text prompts. We then leverage the model's inherent grounding capabilities to score specific image regions (both objects and background) that are semantically relevant to the prompt. Once all region-specific scores are obtained, they are aggregated into a rewards map, which is aligned with the generator's latent space via interpolation for seamless integration into the training pipeline. 
                </p>
            </div>
            
            <div id="sec:judgment" class="sub-section">
                <h2 class="text">2. Self-Judgment Design</h2>
                <p class="text">
                    Our judgment design uses a multi-level scoring mechanism to achieve a fine-grained evaluation. We strictly define the scoring range from -1.0 to 1.0 to constrain bias. The system provides two types of feedback:
                </p>
                <ul>
                        <li><strong>Global Reward \(\alpha\)</strong>: A single scalar score that assesses the overall compositional quality and layout of the entire image. </li>
                        <li><strong>Local Reward \(\mathcal{R}\)</strong>: A dense reward map where each region is scored based on its alignment with specific keywords from the prompt, avoiding interference from irrelevant backgrounds. </li>
                </ul>
                <p class="text">
                    This dual-reward system allows the model to refine both the macro-structure and the micro-details of the generated image. 
                </p>
            </div>

            <div id="sec:objective" class="sub-section">
                <h2 class="text">3. Weighted Post-Training Objective</h2>

                <p class="text">
                    The final training objective \(\mathcal{L}_{~~\text{Total}}\) is a composite loss designed to incorporate the reward feedback while preserving the image's structural integrity. It consists of two main components:
                </p>

                <ol>
                    <li>A <strong>reward-driven term (\(\mathcal{L}_{~\text{r}}\))</strong> that uses the global (\(\alpha\)) and local (\(\mathcal{R}\)) rewards to modulate the learning process, encouraging desired changes (preservation) or penalizing flaws (repulsion). </li>
                    <li>A <strong>ground-truth constraint term (\(\mathcal{L}_{~\text{ref}}\))</strong> that acts as a regularizer, preventing the model from making drastic changes that distort the overall image structure. </li>
                </ol>

                <p class="text">
                    The combined loss is formulated as: \(\mathcal{L}_{~~\text{Total}} = \mathcal{L}_{~\text{r}} + \lambda_{~\text{c}} \cdot \mathcal{L}_{~\text{ref}}\)
                </p>
        </div>

        <div id='Results' class="vision-block">
            <h1 class="text">Experimental Results</h1>
            <p class="text">
                We evaluated SRUM on several unified models, including <strong>Bagel</strong>, <strong>BLIP3o</strong>, and <strong>OmniGen2</strong>, using prompt words from the T2I-CompBench training set. Our results show that SRUM significantly improves the layout and reasoning capabilities of these models, especially on complex composition and counting tasks.
            </p>
            <div style="display: flex; flex-direction: column; align-items: center;" class="figure">
                <div class="table-container">
                    <table class="data-table">
                        <thead>
                            <tr>
                                <th>Model</th>
                                <th>3d spatial</th>
                                <th>Color</th>
                                <th>Complex</th>
                                <th>Nonspatial</th>
                                <th>Numeracy</th>
                                <th>Shape</th>
                                <th>Spatial</th>
                                <th>Texture</th>
                                <th>Overall</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Bagel</td>
                                <td>77.98</td>
                                <td>89.30</td>
                                <td>83.32</td>
                                <td>85.03</td>
                                <td>70.40</td>
                                <td>81.94</td>
                                <td>81.52</td>
                                <td>87.93</td>
                                <td>82.18</td>
                            </tr>
                            <tr style="background-color: rgba(0, 255, 0, 0.1);">
                                <td>Bagel<sub>+SRUM</sub></td>
                                <td class="highlight">83.10</td>
                                <td class="highlight">92.90</td>
                                <td class="highlight">88.69</td>
                                <td class="highlight">88.47</td>
                                <td class="highlight">78.52</td>
                                <td class="highlight">84.23</td>
                                <td class="highlight">86.92</td>
                                <td class="highlight">89.57</td>
                                <td class="highlight">86.55</td>
                            </tr>
                            <tr>
                                <td>BLIP3o</td>
                                <td>81.73</td>
                                <td>89.92</td>
                                <td>85.55</td>
                                <td>84.78</td>
                                <td>71.67</td>
                                <td>83.75</td>
                                <td>92.47</td>
                                <td>87.45</td>
                                <td>84.66</td>
                            </tr>
                            <tr style="background-color: rgba(0, 255, 0, 0.1);">
                                <td>BLIP3o<sub>+SRUM</sub></td>
                                <td class="highlight">83.78</td>
                                <td class="highlight">90.22</td>
                                <td class="highlight">86.57</td>
                                <td class="highlight">85.10</td>
                                <td class="highlight">74.52</td>
                                <td class="highlight">85.44</td>
                                <td class="highlight">93.88</td>
                                <td>86.52</td>
                                <td class="highlight">85.75</td>
                            </tr>
                            <tr>
                                <td>OmniGen2</td>
                                <td>82.21</td>
                                <td>92.22</td>
                                <td>86.87</td>
                                <td>88.51</td>
                                <td>72.00</td>
                                <td>83.95</td>
                                <td>90.07</td>
                                <td>90.88</td>
                                <td>85.84</td>
                            </tr>
                            <tr style="background-color: rgba(0, 255, 0, 0.1);">
                                <td>OmniGen2<sub>+SRUM</sub></td>
                                <td class="highlight">84.39</td>
                                <td>92.00</td>
                                <td class="highlight">87.82</td>
                                <td>88.14</td>
                                <td class="highlight">72.95</td>
                                <td>83.35</td>
                                <td class="highlight">90.67</td>
                                <td>90.65</td>
                                <td class="highlight">86.25</td>
                            </tr>
                            <tr>
                                <td>Bagel (CoT)</td>
                                <td>84.66</td>
                                <td>88.85</td>
                                <td>86.10</td>
                                <td>85.64</td>
                                <td>75.36</td>
                                <td>84.33</td>
                                <td>82.71</td>
                                <td>88.07</td>
                                <td>84.46</td>
                            </tr>
                            <tr style="background-color: rgba(0, 255, 0, 0.1);">
                                <td>Bagel<sub>+SRUM</sub> (CoT)</td>
                                <td class="highlight">88.60</td>
                                <td class="highlight">92.90</td>
                                <td class="highlight">91.31</td>
                                <td class="highlight">90.48</td>
                                <td class="highlight">80.12</td>
                                <td class="highlight">84.47</td>
                                <td class="highlight">89.93</td>
                                <td class="highlight">89.15</td>
                                <td class="highlight">88.37</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
                <figcaption style="text-align: left; width: 100%;">
                    <strong>Table 1:</strong> Complete results of T2I-CompBench. Models integrating the SRUM method show consistent and significant improvements across multiple combination categories. Highlighted cells indicate performance gains from SRUM.
                </figcaption>
            </div>
        </div>
        
        <div id='Analysis' class="vision-block">
            <h1 class="text">Analysis and Insights</h1>
            <p class="text">
                We conducted extensive empirical studies to understand why SRUM is so effective. Our analysis reveals key insights into the roles of different components and their impact on the generation process.
            </p>

            <div id="sec:ablation" class="sub-section">
                <h2 class="text">Ablation Studies: What Matters Most?</h2>
                <p class="text">
                    Our ablation studies on T2I-CompBench highlight the critical role of each component in SRUM. We found that:
                    <ul>
                        <li>The <strong>KL constraint</strong> is crucial for preventing the model from "reward hacking" and deviating too far from a stable policy, a finding consistent with other post-training methods like DPO. </li>
                        <li>Removing the <strong>Global Reward</strong> or using a simple binarized reward leads to significant performance degradation, confirming the value of our fine-grained, multi-level feedback system. </li>
                    </ul>
                </p>
                <d-figure>
                    <figure>
                        <img data-zoomable="" draggable="false" src="static/img/ab_study.png" alt="Ablation Study Results">
                        <figcaption style="text-align: left; width: 100%;">
                            <strong>Figure 2:</strong> Ablation results on T2I-CompBench. The full SRUM method outperforms variants where key components like the Global Reward or KL constraint are removed. 
                        </figcaption>
                    </figure>
                </d-figure>
            </div>
            
            <div id="sec:inference_analysis" class="sub-section">
                <h2 class="text">Analysis of the Inference Process</h2>
                <p class="text">
                    To get a more granular view, we scored the model's output at each step of the inference process for both "layout" and "detail" quality. This step-by-step analysis revealed that improvements in <strong>layout quality</strong> tend to appear in the early stages of inference, driven by chain-of-thought reasoning and the global reward. In contrast, enhancements in <strong>fine-grained details</strong> become more apparent in the later stages, showcasing the impact of the local rewards.
                </p>
                <d-figure>
                    <figure>
                        <img data-zoomable="" draggable="false" src="static/img/plot_layout_score_comparisons_absolute.png" alt="Inference Process Layout Analysis">
                        <figcaption style="text-align: left; width: 100%;">
                            <strong>Figure 3:</strong> Layout scores at different inference steps. Global rewards primarily boost layout early on.
                        </figcaption>
                    </figure>
                </d-figure>
                <d-figure>
                    <figure>
                        <img data-zoomable="" draggable="false" src="static/img/plot_detail_score_comparisons_absolute.png" alt="Inference Process Detail Analysis">
                        <figcaption style="text-align: left; width: 100%;">
                            <strong>Figure 4:</strong> Detail scores at different inference steps. Detail refinement occurs later, showcasing the impact of local rewards.
                        </figcaption>
                    </figure>
                </d-figure>
            </div>
            
            <div id="sec:generalization" class="sub-section">
                <h2 class="text">Impressive Generalization</h2>
                <p class="text">
                    SRUM demonstrates robust generalization to tasks and domains it wasn't explicitly trained on.
                    <ul>
                        <li><strong>In-Domain Generalization</strong>: The model shows strong performance on the GenEval benchmark even when trained only on T2I-CompBench data, proving that the learned skills are transferable. </li>
                        <li><strong>Out-of-Domain Generalization</strong>: When tested on the challenging T2I-ReasonBench, the SRUM-trained model achieves superior understanding of complex, reasoning-based prompts compared to baseline and SFT models. </li>
                    </ul>
                </p>
                <d-figure>
                    <figure>
                        <div style="display: flex; gap: 20px; justify-content: center; flex-wrap: wrap;">
                            <img data-zoomable draggable="false" id="displayLeftImage" src="static/img/wise.jpg" alt="WISE Benchmark" style="max-width: 100%; height: auto; border-radius: 8px;">
                            <img data-zoomable draggable="false" id="displayRightImage" src="static/img/reasonbench.jpg" alt="ReasonBench Results" style="max-width: 100%; height: auto; border-radius: 8px;">
                        </div>
                        <figcaption style="text-align: left; width: 100%;">
                            <strong>Figure 5:</strong> SRUM shows strong knowledge transfer on the WISE benchmark (top) and superior reasoning accuracy on the T2I-ReasonBench (bottom). 
                        </figcaption>
                    </figure>
                </d-figure>
            </div>



        </div>

        <div id="discussion" style="position: relative; margin-top: 40px; margin-bottom: 0px;">
            <h2 class="text" style="margin-top:0px; margin-bottom:10px">Discussion</h2>
            <p class="text">
                SRUM is just a preliminary exploration of Unified Models (UMs). We found that there is still room for improvement in the prompts for the understanding part during the scoring phase, and we hope to scale this method to larger datasets. This article also utilizes some external prompts to improve performance for illustrative purposes. In fact, it is entirely possible to allow the understanding part to <strong>self-play questions and answers</strong> to build a more closed-loop training system.
            </p>
        </div>

        <div id="conclusion" style="position: relative; margin-top: 40px; margin-bottom: 0px;">
            <h2 class="text" style="margin-top:0px; margin-bottom:10px">Conclusion</h2>
            <p class="text">
                SRUM is a self-rewarding framework that enhances compositional reasoning in unified models. It moves beyond costly external judges by leveraging a model's inherent understanding-generation duality. The model's comprehension module provides fine-grained, internal reward signals to its generative counterpart, creating an efficient optimization loop. Rewards are decomposed into global composition and local attribute fidelity for multi-scale alignment. Experiments on T2I-CompBench and T2I-ReasonBench show significant performance gains and strong generalization, validating the framework's effectiveness and potential for future multimodal applications.
            </p>
        </div>

        </d-article>
        <d-appendix>
        <h3>BibTeX</h3>
        <p class="bibtex">
            @article{jin2025srum,<br>
            &nbsp;&nbsp;title={SRUM: Fine-Grained Self-Rewarding for Unified Models},<br>
            &nbsp;&nbsp;author={Jin, Weiyang and Niu, Yuwei and Liao, Jiaqi and Duan, Chengqi and Liu, Xihui},<br>
            &nbsp;&nbsp;journal={arXiv preprint arXiv:your_arxiv_id},<br>
            &nbsp;&nbsp;year={2025}<br>
            }
        </p>

        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
    </d-appendix>


    <d-bibliography src="bibliography.bib"></d-bibliography>
    <script src="./static/js/nav-bar.js"></script>

    <footer class="site-footer" style="padding: 2rem 0; text-align:center; font-size:1rem;">
        <div class="footerSection" style="margin-bottom:0.5rem;">
            <p>Website template adapted from <a href="https://github.com/facebookresearch/metaquery">MetaQuery</a>.</p>
        </div>
        <p style="margin:0;">Copyright © 2025</p>
    </footer>
</body>
</html>